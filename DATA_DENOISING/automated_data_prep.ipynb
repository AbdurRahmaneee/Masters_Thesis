{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac75c941-f8c7-499b-bca4-bd19221b79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "def extract_test_id(file_name):\n",
    "    \"\"\"\n",
    "    Extracts the test ID from the file name.\n",
    "    \"\"\"\n",
    "    parts = file_name.split(\"_\")\n",
    "    return f\"{parts[0]}_{parts[1]}\"\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"\n",
    "    Processes a single data file to extract peak frequencies and amplitudes.\n",
    "    \"\"\"\n",
    "    # Extract the test ID and channel number from the file name\n",
    "    file_name = os.path.basename(file_path)\n",
    "    test_id = extract_test_id(file_name)\n",
    "\n",
    "\n",
    "    # Load the data\n",
    "    data = np.loadtxt(file_path)\n",
    "\n",
    "    # Use Short-Time Fourier Transform (STFT) to extract the frequency components\n",
    "    f, t, Zxx = signal.stft(data, fs=1/0.000019531, nperseg=50000*5)\n",
    "\n",
    "    # Identify the frequency bins that contain the noise and its harmonics\n",
    "    noise_bins = np.where((f > 190) & (f < 210))[0]\n",
    "    harmonics_bins = np.where((f > 380) & (f < 420))[0]\n",
    "    harmonics_bins_2 = np.where((f > 760) & (f < 840))[0]\n",
    "    combined_bins = np.concatenate((noise_bins, harmonics_bins, harmonics_bins_2))\n",
    "\n",
    "    # Apply a binary mask to the STFT output to zero out the noise and its harmonics\n",
    "    mask = np.ones(Zxx.shape)\n",
    "    mask[combined_bins] = 0\n",
    "\n",
    "    # Inverse STFT to obtain the denoised signal\n",
    "    _, denoised_data = signal.istft(mask * Zxx)\n",
    "\n",
    "    # Convert the denoised data back to the original time domain\n",
    "    denoised_data = np.real(denoised_data)\n",
    "\n",
    "    # performing fft on filtered data or denoised data\n",
    "    sr = 1/0.000019531 # sampling rate (Hz)\n",
    "    X = scipy.fft.fft(denoised_data) # fft performed\n",
    "    n = np.arange(len(X)) #length of fft\n",
    "    T = len(X)/sr # sampling period\n",
    "    x_freq = n/T\n",
    "\n",
    "    # find peaks in the plot\n",
    "    peaks, props = scipy.signal.find_peaks(np.abs(X[:int(len(X)*20000//sr)]), height=5, distance=100000)\n",
    "\n",
    "    # Get the frequencies of the peaks\n",
    "    peak_amplitudes = props['peak_heights']\n",
    "    peak_frequencies = x_freq[peaks]\n",
    "    # Sort the peak amplitudes in descending order\n",
    "    sorted_indices = np.argsort(-peak_amplitudes)\n",
    "\n",
    "    # Get the top 17 frequencies\n",
    "    top_17_frequencies = peak_frequencies[sorted_indices[:17]]\n",
    "    # Create a row for the current data file\n",
    "    data_row = [test_id] + top_17_frequencies.tolist()\n",
    "\n",
    "    return data_row\n",
    "\n",
    "def process_files(file_paths):\n",
    "    \"\"\"\n",
    "    Processes a list of data files and returns a Pandas DataFrame with peak frequencies and amplitudes.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "\n",
    "    # Loop through the file paths and process each file\n",
    "    for file_path in file_paths:\n",
    "        # Process the current file to get the peak frequencies\n",
    "        data_row = process_file(file_path)\n",
    "\n",
    "        # Extract the test ID from the data row\n",
    "        test_id = data_row[0]\n",
    "\n",
    "        # Add the peak frequencies to the dictionary\n",
    "        if test_id in data_dict:\n",
    "            data_dict[test_id] += data_row[1:]\n",
    "        else:\n",
    "            data_dict[test_id] = data_row[1:]\n",
    "\n",
    "\n",
    "    # Create a list of data rows for the DataFrame\n",
    "    data_rows = []\n",
    "    for test_id, peak_frequencies in data_dict.items():\n",
    "         data_rows.append([test_id] + peak_frequencies)\n",
    "\n",
    "    # Create a Pandas DataFrame with the processed data\n",
    "    column_names = [\"Test ID\"] + [f\"Peak {i}\" for i in range(1, len(data_rows[0]))]\n",
    "    df = pd.DataFrame(data_rows, columns=column_names)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(\"peak_auto.csv\", index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Define the directory containing the data files\n",
    "data_dir = \"RAW_DATA\"\n",
    "\n",
    "# Get a list of file paths in the data directory\n",
    "file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
    "\n",
    "# Process the files and generate a DataFrame\n",
    "process_files(file_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
